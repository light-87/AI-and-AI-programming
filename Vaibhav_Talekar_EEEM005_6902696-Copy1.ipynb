{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1wcnjQODYQ4"
   },
   "source": [
    "# ***0. Data Loading***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "n6MJyx0bDlFa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>unas</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>333333.321500</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.885807</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>2934</td>\n",
       "      <td>3742</td>\n",
       "      <td>118.535982</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.538781</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>FIN</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>818</td>\n",
       "      <td>1076</td>\n",
       "      <td>31.552710</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>125000.000300</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.448734</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>1476</td>\n",
       "      <td>822</td>\n",
       "      <td>55.712295</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
       "0   1  0.000003  unas       -   INT      2      0     200       0   \n",
       "1   2  0.885807   tcp     ftp   FIN     52     54    2934    3742   \n",
       "2   3  0.538781   tcp    http   FIN     10      8     818    1076   \n",
       "3   4  0.000008   udp     dns   INT      2      0     114       0   \n",
       "4   5  0.448734   tcp     ftp   FIN     14     12    1476     822   \n",
       "\n",
       "            rate  ...  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
       "0  333333.321500  ...                 4                 4               5   \n",
       "1     118.535982  ...                 1                 1               3   \n",
       "2      31.552710  ...                 2                 1               5   \n",
       "3  125000.000300  ...                27                13              34   \n",
       "4      55.712295  ...                 1                 1               1   \n",
       "\n",
       "   is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  \\\n",
       "0             0           0                 0           8          11   \n",
       "1             1           1                 0           5           1   \n",
       "2             0           0                 1           2           6   \n",
       "3             0           0                 0          27          34   \n",
       "4             0           0                 0           1           1   \n",
       "\n",
       "   is_sm_ips_ports  label  \n",
       "0                0      1  \n",
       "1                0      0  \n",
       "2                0      0  \n",
       "3                0      1  \n",
       "4                0      1  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import time\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "df = pd.read_csv(\"UNSWNB15_training_coursework.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 44 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 20000 non-null  int64  \n",
      " 1   dur                20000 non-null  float64\n",
      " 2   proto              20000 non-null  object \n",
      " 3   service            20000 non-null  object \n",
      " 4   state              20000 non-null  object \n",
      " 5   spkts              20000 non-null  int64  \n",
      " 6   dpkts              20000 non-null  int64  \n",
      " 7   sbytes             20000 non-null  int64  \n",
      " 8   dbytes             20000 non-null  int64  \n",
      " 9   rate               20000 non-null  float64\n",
      " 10  sttl               20000 non-null  int64  \n",
      " 11  dttl               20000 non-null  int64  \n",
      " 12  sload              20000 non-null  float64\n",
      " 13  dload              20000 non-null  float64\n",
      " 14  sloss              20000 non-null  int64  \n",
      " 15  dloss              20000 non-null  int64  \n",
      " 16  sinpkt             20000 non-null  float64\n",
      " 17  dinpkt             20000 non-null  float64\n",
      " 18  sjit               20000 non-null  float64\n",
      " 19  djit               20000 non-null  float64\n",
      " 20  swin               20000 non-null  int64  \n",
      " 21  stcpb              20000 non-null  int64  \n",
      " 22  dtcpb              20000 non-null  int64  \n",
      " 23  dwin               20000 non-null  int64  \n",
      " 24  tcprtt             20000 non-null  float64\n",
      " 25  synack             20000 non-null  float64\n",
      " 26  ackdat             20000 non-null  float64\n",
      " 27  smean              20000 non-null  int64  \n",
      " 28  dmean              20000 non-null  int64  \n",
      " 29  trans_depth        20000 non-null  int64  \n",
      " 30  response_body_len  20000 non-null  int64  \n",
      " 31  ct_srv_src         20000 non-null  int64  \n",
      " 32  ct_state_ttl       20000 non-null  int64  \n",
      " 33  ct_dst_ltm         20000 non-null  int64  \n",
      " 34  ct_src_dport_ltm   20000 non-null  int64  \n",
      " 35  ct_dst_sport_ltm   20000 non-null  int64  \n",
      " 36  ct_dst_src_ltm     20000 non-null  int64  \n",
      " 37  is_ftp_login       20000 non-null  int64  \n",
      " 38  ct_ftp_cmd         20000 non-null  int64  \n",
      " 39  ct_flw_http_mthd   20000 non-null  int64  \n",
      " 40  ct_src_ltm         20000 non-null  int64  \n",
      " 41  ct_srv_dst         20000 non-null  int64  \n",
      " 42  is_sm_ips_ports    20000 non-null  int64  \n",
      " 43  label              20000 non-null  int64  \n",
      "dtypes: float64(11), int64(30), object(3)\n",
      "memory usage: 6.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dur</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sload</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>2.000000e+04</td>\n",
       "      <td>2.000000e+04</td>\n",
       "      <td>2.000000e+04</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>2.000000e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10000.500000</td>\n",
       "      <td>0.984361</td>\n",
       "      <td>17.665100</td>\n",
       "      <td>16.328650</td>\n",
       "      <td>7.199524e+03</td>\n",
       "      <td>1.181382e+04</td>\n",
       "      <td>8.284978e+04</td>\n",
       "      <td>182.044500</td>\n",
       "      <td>95.980700</td>\n",
       "      <td>6.351236e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>4.995200</td>\n",
       "      <td>3.712400</td>\n",
       "      <td>7.538100</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.008050</td>\n",
       "      <td>0.128900</td>\n",
       "      <td>6.516900</td>\n",
       "      <td>9.226950</td>\n",
       "      <td>0.01095</td>\n",
       "      <td>0.556800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5773.647028</td>\n",
       "      <td>4.623803</td>\n",
       "      <td>127.429883</td>\n",
       "      <td>79.351286</td>\n",
       "      <td>1.638553e+05</td>\n",
       "      <td>1.018836e+05</td>\n",
       "      <td>1.489504e+05</td>\n",
       "      <td>101.046988</td>\n",
       "      <td>116.877854</td>\n",
       "      <td>1.759982e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>8.525521</td>\n",
       "      <td>5.991734</td>\n",
       "      <td>11.566518</td>\n",
       "      <td>0.089086</td>\n",
       "      <td>0.089362</td>\n",
       "      <td>0.575066</td>\n",
       "      <td>8.657936</td>\n",
       "      <td>11.259329</td>\n",
       "      <td>0.10407</td>\n",
       "      <td>0.496776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5000.750000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.140000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.818181e+01</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.118980e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10000.500000</td>\n",
       "      <td>0.013746</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.340000e+02</td>\n",
       "      <td>1.780000e+02</td>\n",
       "      <td>2.680967e+03</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.857572e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15000.250000</td>\n",
       "      <td>0.717441</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.268000e+03</td>\n",
       "      <td>8.585000e+02</td>\n",
       "      <td>1.250000e+05</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>6.514286e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>59.995674</td>\n",
       "      <td>9392.000000</td>\n",
       "      <td>3504.000000</td>\n",
       "      <td>1.250037e+07</td>\n",
       "      <td>4.750303e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>5.268000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id           dur         spkts         dpkts        sbytes  \\\n",
       "count  20000.000000  20000.000000  20000.000000  20000.000000  2.000000e+04   \n",
       "mean   10000.500000      0.984361     17.665100     16.328650  7.199524e+03   \n",
       "std     5773.647028      4.623803    127.429883     79.351286  1.638553e+05   \n",
       "min        1.000000      0.000000      1.000000      0.000000  2.400000e+01   \n",
       "25%     5000.750000      0.000008      2.000000      0.000000  1.140000e+02   \n",
       "50%    10000.500000      0.013746      6.000000      2.000000  5.340000e+02   \n",
       "75%    15000.250000      0.717441     12.000000     10.000000  1.268000e+03   \n",
       "max    20000.000000     59.995674   9392.000000   3504.000000  1.250037e+07   \n",
       "\n",
       "             dbytes          rate          sttl          dttl         sload  \\\n",
       "count  2.000000e+04  2.000000e+04  20000.000000  20000.000000  2.000000e+04   \n",
       "mean   1.181382e+04  8.284978e+04    182.044500     95.980700  6.351236e+07   \n",
       "std    1.018836e+05  1.489504e+05    101.046988    116.877854  1.759982e+08   \n",
       "min    0.000000e+00  0.000000e+00      0.000000      0.000000  0.000000e+00   \n",
       "25%    0.000000e+00  2.818181e+01     62.000000      0.000000  1.118980e+04   \n",
       "50%    1.780000e+02  2.680967e+03    254.000000     29.000000  5.857572e+05   \n",
       "75%    8.585000e+02  1.250000e+05    254.000000    252.000000  6.514286e+07   \n",
       "max    4.750303e+06  1.000000e+06    255.000000    253.000000  5.268000e+09   \n",
       "\n",
       "       ...  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
       "count  ...      20000.000000      20000.000000    20000.000000  20000.000000   \n",
       "mean   ...          4.995200          3.712400        7.538100      0.008000   \n",
       "std    ...          8.525521          5.991734       11.566518      0.089086   \n",
       "min    ...          1.000000          1.000000        1.000000      0.000000   \n",
       "25%    ...          1.000000          1.000000        1.000000      0.000000   \n",
       "50%    ...          1.000000          1.000000        3.000000      0.000000   \n",
       "75%    ...          4.000000          3.000000        6.000000      0.000000   \n",
       "max    ...         59.000000         37.000000       63.000000      1.000000   \n",
       "\n",
       "         ct_ftp_cmd  ct_flw_http_mthd    ct_src_ltm    ct_srv_dst  \\\n",
       "count  20000.000000      20000.000000  20000.000000  20000.000000   \n",
       "mean       0.008050          0.128900      6.516900      9.226950   \n",
       "std        0.089362          0.575066      8.657936     11.259329   \n",
       "min        0.000000          0.000000      1.000000      1.000000   \n",
       "25%        0.000000          0.000000      1.000000      2.000000   \n",
       "50%        0.000000          0.000000      3.000000      5.000000   \n",
       "75%        0.000000          0.000000      7.000000     11.000000   \n",
       "max        1.000000         16.000000     60.000000     59.000000   \n",
       "\n",
       "       is_sm_ips_ports         label  \n",
       "count      20000.00000  20000.000000  \n",
       "mean           0.01095      0.556800  \n",
       "std            0.10407      0.496776  \n",
       "min            0.00000      0.000000  \n",
       "25%            0.00000      0.000000  \n",
       "50%            0.00000      1.000000  \n",
       "75%            0.00000      1.000000  \n",
       "max            1.00000      1.000000  \n",
       "\n",
       "[8 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "dur                  0\n",
       "proto                0\n",
       "service              0\n",
       "state                0\n",
       "spkts                0\n",
       "dpkts                0\n",
       "sbytes               0\n",
       "dbytes               0\n",
       "rate                 0\n",
       "sttl                 0\n",
       "dttl                 0\n",
       "sload                0\n",
       "dload                0\n",
       "sloss                0\n",
       "dloss                0\n",
       "sinpkt               0\n",
       "dinpkt               0\n",
       "sjit                 0\n",
       "djit                 0\n",
       "swin                 0\n",
       "stcpb                0\n",
       "dtcpb                0\n",
       "dwin                 0\n",
       "tcprtt               0\n",
       "synack               0\n",
       "ackdat               0\n",
       "smean                0\n",
       "dmean                0\n",
       "trans_depth          0\n",
       "response_body_len    0\n",
       "ct_srv_src           0\n",
       "ct_state_ttl         0\n",
       "ct_dst_ltm           0\n",
       "ct_src_dport_ltm     0\n",
       "ct_dst_sport_ltm     0\n",
       "ct_dst_src_ltm       0\n",
       "is_ftp_login         0\n",
       "ct_ftp_cmd           0\n",
       "ct_flw_http_mthd     0\n",
       "ct_src_ltm           0\n",
       "ct_srv_dst           0\n",
       "is_sm_ips_ports      0\n",
       "label                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service: 13 unique values\n",
      "state: 4 unique values\n",
      "sttl: 9 unique values\n",
      "dttl: 7 unique values\n",
      "swin: 4 unique values\n",
      "dwin: 4 unique values\n",
      "trans_depth: 6 unique values\n",
      "ct_state_ttl: 6 unique values\n",
      "is_ftp_login: 2 unique values\n",
      "ct_ftp_cmd: 2 unique values\n",
      "ct_flw_http_mthd: 8 unique values\n",
      "is_sm_ips_ports: 2 unique values\n",
      "label: 2 unique values\n"
     ]
    }
   ],
   "source": [
    "df[\"label\"].value_counts()\n",
    "\n",
    "categori_cols = []\n",
    "for col in df.columns:\n",
    "    if df[col].nunique() < 25:\n",
    "        categori_cols.append(col)\n",
    "        print(f\"{col}: {df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: service\n",
      "service\n",
      "-       11296\n",
      "dns      5256\n",
      "http     2096\n",
      "smtp      454\n",
      "ftp       385\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Column: state\n",
      "state\n",
      "FIN    9530\n",
      "INT    8357\n",
      "CON    1662\n",
      "REQ     451\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Column: sttl\n",
      "sttl\n",
      "254    13222\n",
      "31      3977\n",
      "62      2531\n",
      "0        237\n",
      "29         8\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Column: dttl\n",
      "dttl\n",
      "0      8820\n",
      "252    7147\n",
      "29     3969\n",
      "60       44\n",
      "30       13\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Column: swin\n",
      "swin\n",
      "255    10436\n",
      "0       9562\n",
      "67         1\n",
      "154        1\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Column: dwin\n",
      "dwin\n",
      "255    10022\n",
      "0       9976\n",
      "137        1\n",
      "77         1\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Column: trans_depth\n",
      "trans_depth\n",
      "0    18093\n",
      "1     1899\n",
      "2        5\n",
      "8        1\n",
      "9        1\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Column: ct_state_ttl\n",
      "ct_state_ttl\n",
      "2    8346\n",
      "1    6658\n",
      "0    4046\n",
      "3     500\n",
      "6     443\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Column: is_ftp_login\n",
      "is_ftp_login\n",
      "0    19840\n",
      "1      160\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Column: ct_ftp_cmd\n",
      "ct_ftp_cmd\n",
      "0    19839\n",
      "1      161\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Column: ct_flw_http_mthd\n",
      "ct_flw_http_mthd\n",
      "0    18095\n",
      "1     1743\n",
      "4      117\n",
      "9       35\n",
      "2        6\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Column: is_sm_ips_ports\n",
      "is_sm_ips_ports\n",
      "0    19781\n",
      "1      219\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "\n",
      "Column: label\n",
      "label\n",
      "1    11136\n",
      "0     8864\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for col in categori_cols:\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(df[col].value_counts().head())\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYce1Z49mIsz"
   },
   "source": [
    "# ***1. Data Pre-Processing (Task 1)***\n",
    "\n",
    "- We need to encode categorical features since the RBFN model requires numerical inputs.\n",
    "- For categorical columns like 'service' and 'state', we'll use one-hot encoding.\n",
    "- For 'proto', which has many unique values, we'll keep top 10 and group the rest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "A0DbTy5EA0f2"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(df, categorical_cols):\n",
    "    df_encoded = df.copy()\n",
    "    for col in categorical_cols:\n",
    "        if col in df_encoded.columns:\n",
    "            dummies = pd.get_dummies(df_encoded[col], prefix=col, drop_first=False)\n",
    "            df_encoded = pd.concat([df_encoded, dummies], axis=1)\n",
    "            df_encoded.drop(col, axis=1, inplace=True)\n",
    "    return df_encoded\n",
    "\n",
    "cats_to_encode = ['service', 'state']\n",
    "df_encoded = one_hot_encode(df, cats_to_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_protocol(df, column='proto', top_n=10):\n",
    "    value_counts = df[column].value_counts()\n",
    "    top_values = value_counts.head(top_n).index.tolist()\n",
    "    \n",
    "    df_encoded = df.copy()\n",
    "    df_encoded[column] = df_encoded[column].apply(lambda x: x if x in top_values else 'other')\n",
    "    \n",
    "    proto_encoded = pd.get_dummies(df_encoded[column], prefix=column, drop_first=False)\n",
    "    df_encoded = pd.concat([df_encoded, proto_encoded], axis=1)\n",
    "    \n",
    "    df_encoded.drop(column, axis=1, inplace=True)\n",
    "    \n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 69 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 20000 non-null  int64  \n",
      " 1   dur                20000 non-null  float64\n",
      " 2   spkts              20000 non-null  int64  \n",
      " 3   dpkts              20000 non-null  int64  \n",
      " 4   sbytes             20000 non-null  int64  \n",
      " 5   dbytes             20000 non-null  int64  \n",
      " 6   rate               20000 non-null  float64\n",
      " 7   sttl               20000 non-null  int64  \n",
      " 8   dttl               20000 non-null  int64  \n",
      " 9   sload              20000 non-null  float64\n",
      " 10  dload              20000 non-null  float64\n",
      " 11  sloss              20000 non-null  int64  \n",
      " 12  dloss              20000 non-null  int64  \n",
      " 13  sinpkt             20000 non-null  float64\n",
      " 14  dinpkt             20000 non-null  float64\n",
      " 15  sjit               20000 non-null  float64\n",
      " 16  djit               20000 non-null  float64\n",
      " 17  swin               20000 non-null  int64  \n",
      " 18  stcpb              20000 non-null  int64  \n",
      " 19  dtcpb              20000 non-null  int64  \n",
      " 20  dwin               20000 non-null  int64  \n",
      " 21  tcprtt             20000 non-null  float64\n",
      " 22  synack             20000 non-null  float64\n",
      " 23  ackdat             20000 non-null  float64\n",
      " 24  smean              20000 non-null  int64  \n",
      " 25  dmean              20000 non-null  int64  \n",
      " 26  trans_depth        20000 non-null  int64  \n",
      " 27  response_body_len  20000 non-null  int64  \n",
      " 28  ct_srv_src         20000 non-null  int64  \n",
      " 29  ct_state_ttl       20000 non-null  int64  \n",
      " 30  ct_dst_ltm         20000 non-null  int64  \n",
      " 31  ct_src_dport_ltm   20000 non-null  int64  \n",
      " 32  ct_dst_sport_ltm   20000 non-null  int64  \n",
      " 33  ct_dst_src_ltm     20000 non-null  int64  \n",
      " 34  is_ftp_login       20000 non-null  int64  \n",
      " 35  ct_ftp_cmd         20000 non-null  int64  \n",
      " 36  ct_flw_http_mthd   20000 non-null  int64  \n",
      " 37  ct_src_ltm         20000 non-null  int64  \n",
      " 38  ct_srv_dst         20000 non-null  int64  \n",
      " 39  is_sm_ips_ports    20000 non-null  int64  \n",
      " 40  label              20000 non-null  int64  \n",
      " 41  service_-          20000 non-null  bool   \n",
      " 42  service_dhcp       20000 non-null  bool   \n",
      " 43  service_dns        20000 non-null  bool   \n",
      " 44  service_ftp        20000 non-null  bool   \n",
      " 45  service_ftp-data   20000 non-null  bool   \n",
      " 46  service_http       20000 non-null  bool   \n",
      " 47  service_irc        20000 non-null  bool   \n",
      " 48  service_pop3       20000 non-null  bool   \n",
      " 49  service_radius     20000 non-null  bool   \n",
      " 50  service_smtp       20000 non-null  bool   \n",
      " 51  service_snmp       20000 non-null  bool   \n",
      " 52  service_ssh        20000 non-null  bool   \n",
      " 53  service_ssl        20000 non-null  bool   \n",
      " 54  state_CON          20000 non-null  bool   \n",
      " 55  state_FIN          20000 non-null  bool   \n",
      " 56  state_INT          20000 non-null  bool   \n",
      " 57  state_REQ          20000 non-null  bool   \n",
      " 58  proto_any          20000 non-null  bool   \n",
      " 59  proto_arp          20000 non-null  bool   \n",
      " 60  proto_gre          20000 non-null  bool   \n",
      " 61  proto_leaf-1       20000 non-null  bool   \n",
      " 62  proto_ospf         20000 non-null  bool   \n",
      " 63  proto_other        20000 non-null  bool   \n",
      " 64  proto_rsvp         20000 non-null  bool   \n",
      " 65  proto_sctp         20000 non-null  bool   \n",
      " 66  proto_tcp          20000 non-null  bool   \n",
      " 67  proto_udp          20000 non-null  bool   \n",
      " 68  proto_unas         20000 non-null  bool   \n",
      "dtypes: bool(28), float64(11), int64(30)\n",
      "memory usage: 6.8 MB\n"
     ]
    }
   ],
   "source": [
    "df_encoded = encode_protocol(df_encoded, column='proto', top_n=10)\n",
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after encoding: (20000, 69)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape after encoding: {df_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "- We'll select features based on their correlation with the target variable.\n",
    "- This helps reduce dimensionality and improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive correlations with target:\n",
      "label               1.000000\n",
      "state_INT           0.539950\n",
      "sttl                0.501182\n",
      "ct_dst_sport_ltm    0.391979\n",
      "service_dns         0.364610\n",
      "ct_src_dport_ltm    0.340933\n",
      "rate                0.327217\n",
      "ct_state_ttl        0.314762\n",
      "ct_srv_dst          0.298652\n",
      "ct_srv_src          0.294529\n",
      "Name: label, dtype: float64\n",
      "\n",
      "Top negative correlations with target:\n",
      "service_radius      -0.001143\n",
      "dur                 -0.002083\n",
      "trans_depth         -0.009842\n",
      "service_ftp         -0.017850\n",
      "response_body_len   -0.019607\n",
      "is_ftp_login        -0.020437\n",
      "ct_ftp_cmd          -0.021001\n",
      "service_http        -0.021706\n",
      "djit                -0.031771\n",
      "spkts               -0.033389\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "target_corrs = df_encoded.corr()['label'].sort_values(ascending=False)\n",
    "\n",
    "print(\"Top positive correlations with target:\")\n",
    "print(target_corrs[target_corrs > 0].head(10))\n",
    "\n",
    "print(\"\\nTop negative correlations with target:\")\n",
    "print(target_corrs[target_corrs < 0].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 8))\n",
    "# top_features = target_corrs.abs().sort_values(ascending=False).head(20).index\n",
    "# sns.barplot(x=target_corrs[top_features], y=top_features)\n",
    "# plt.title('Top 20 Feature Correlations with Target')\n",
    "# plt.xlabel('Correlation Coefficient')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_threshold = 0.1\n",
    "selected_features = target_corrs.abs().sort_values(ascending=False)\n",
    "selected_features = selected_features[selected_features > corr_threshold].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'label' in selected_features:\n",
    "    selected_features.remove('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 34 features with correlation > 0.1\n",
      "Top selected features:\n",
      "['state_INT', 'sttl', 'proto_tcp', 'swin', 'ct_dst_sport_ltm', 'dwin', 'service_dns', 'ct_src_dport_ltm', 'rate', 'state_FIN']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Selected {len(selected_features)} features with correlation > {corr_threshold}\")\n",
    "print(\"Top selected features:\")\n",
    "print(selected_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_features(df, exclude_cols=None):\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = []\n",
    "    \n",
    "    df_std = df.copy()\n",
    "    scaler_params = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col not in exclude_cols:\n",
    "            mean = df[col].mean()\n",
    "            std = df[col].std()\n",
    "            \n",
    "            # Store parameters for later use\n",
    "            scaler_params[col] = {'mean': mean, 'std': std}\n",
    "            \n",
    "            # Apply standardization\n",
    "            if std > 0:\n",
    "                df_std[col] = (df[col] - mean) / std\n",
    "            # If std is 0, leave the column as is\n",
    "    \n",
    "    return df_std, scaler_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std, scaler_params = standardize_features(df_encoded, exclude_cols=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset: 20000 samples with 34 features\n"
     ]
    }
   ],
   "source": [
    "X_cols = selected_features\n",
    "y_col = 'label'\n",
    "\n",
    "X = df_std[X_cols].values\n",
    "y = df_std[y_col].values\n",
    "\n",
    "print(f\"Final dataset: {X.shape[0]} samples with {X.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4uQmeM_Albh"
   },
   "source": [
    "# ***2. Model Implementation and Training (Task 2)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "yzR1gaj0BZlG"
   },
   "outputs": [],
   "source": [
    "class MyRBFN:\n",
    "    def __init__(self, num_centers, sigma=1.0):\n",
    "        self.num_centers = num_centers\n",
    "        self.sigma = sigma\n",
    "        self.centers = None\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def _kmeans(self, X, max_iters=200, tol=1e-4):\n",
    "        n_samples, n_features = X.shape\n",
    "        random_indices = np.random.choice(n_samples, self.num_centers, replace=False)\n",
    "        centers = X[random_indices].copy()\n",
    "        \n",
    "        for iteration in range(max_iters):\n",
    "            distances = np.zeros((n_samples, self.num_centers))\n",
    "            for i, center in enumerate(centers):\n",
    "                diff = X - center\n",
    "                distances[:, i] = np.sum(diff * diff, axis=1)\n",
    "\n",
    "            cluster_assignments = np.argmin(distances, axis=1)\n",
    "            \n",
    "            old_centers = centers.copy()\n",
    "\n",
    "            for i in range(self.num_centers):\n",
    "                cluster_points = X[cluster_assignments == i]\n",
    "                if len(cluster_points) > 0:\n",
    "                    centers[i] = np.mean(cluster_points, axis=0)\n",
    "            \n",
    "            center_shift = np.sum((centers - old_centers) ** 2)\n",
    "            if center_shift < tol:\n",
    "                break\n",
    "        \n",
    "        return centers\n",
    "    \n",
    "    def _calculate_sigma(self, centers):\n",
    "        n_centers = centers.shape[0]\n",
    "        distances = np.zeros((n_centers, n_centers))\n",
    "        \n",
    "        for i in range(n_centers):\n",
    "            for j in range(i+1, n_centers):\n",
    "                dist = np.sqrt(np.sum((centers[i] - centers[j]) ** 2))\n",
    "                distances[i, j] = distances[j, i] = dist\n",
    "        \n",
    "        min_distances = []\n",
    "        for i in range(n_centers):\n",
    "            center_distances = [d for j, d in enumerate(distances[i]) if j != i and d > 0]\n",
    "            if center_distances:\n",
    "                min_distances.append(min(center_distances))\n",
    "        \n",
    "        if not min_distances:\n",
    "            return self.sigma\n",
    "        \n",
    "        sigma = np.mean(min_distances) / math.sqrt(2 * self.num_centers)\n",
    "        return max(sigma, 1e-10)\n",
    "    \n",
    "    def _rbf(self, x, center):\n",
    "        dist = np.sum((x - center) ** 2)\n",
    "        return np.exp(-dist / (2 * self.sigma ** 2))\n",
    "    \n",
    "    def _calculate_interpolation_matrix(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        G = np.zeros((n_samples, self.num_centers))\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            for j in range(self.num_centers):\n",
    "                G[i, j] = self._rbf(X[i], self.centers[j])\n",
    "        \n",
    "        return G\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        print(\"Finding centers using K-means...\")\n",
    "        self.centers = self._kmeans(X)\n",
    "        \n",
    "        # Calculate optimal sigma\n",
    "        # self.sigma = self._calculate_sigma(self.centers)\n",
    "        # print(f\"Using sigma: {self.sigma}\")\n",
    "        \n",
    "        print(\"Calculating interpolation matrix...\")\n",
    "        G = self._calculate_interpolation_matrix(X)\n",
    "        \n",
    "        G_with_bias = np.column_stack((G, np.ones(X.shape[0])))\n",
    "        \n",
    "        print(\"Solving for weights...\")\n",
    "        try:\n",
    "            # Using pseudoinverse: (G^T G)^(-1) G^T y\n",
    "            GTG = np.dot(G_with_bias.T, G_with_bias)\n",
    "            GTG_inv = np.linalg.inv(GTG + np.eye(GTG.shape[0]) * 1e-6)  # Add small regularization\n",
    "            self.weights = np.dot(np.dot(GTG_inv, G_with_bias.T), y)\n",
    "            \n",
    "            # Extract bias term\n",
    "            self.bias = self.weights[-1]\n",
    "            # Keep only RBF weights\n",
    "            self.weights = self.weights[:-1]\n",
    "            \n",
    "            # Calculate training error\n",
    "            y_pred = self.predict(X)\n",
    "            accuracy = np.mean(y_pred == y)\n",
    "            print(f\"Training accuracy: {accuracy:.4f}\")\n",
    "            \n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"Error: Matrix inversion failed. Try reducing the number of centers or adding more regularization.\")\n",
    "            # Set random weights as fallback\n",
    "            self.weights = np.random.randn(self.num_centers)\n",
    "            self.bias = 0\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        \n",
    "        G = self._calculate_interpolation_matrix(X)\n",
    "        \n",
    "        y_pred_raw = np.dot(G, self.weights) + self.bias\n",
    "        \n",
    "        y_pred = (y_pred_raw > 0.5).astype(int)\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = np.array(X)\n",
    "        \n",
    "        G = self._calculate_interpolation_matrix(X)\n",
    "        \n",
    "        y_pred_raw = np.dot(G, self.weights) + self.bias\n",
    "        \n",
    "        y_proba = 1 / (1 + np.exp(-y_pred_raw))\n",
    "        \n",
    "        return y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    total = tp + tn + fp + fn\n",
    "    accuracy = (tp + tn) / total if total > 0 else 0\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    sensitivity = recall\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    balanced_acc = (sensitivity + specificity) / 2\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'balanced_accuracy': balanced_acc,\n",
    "        'confusion_matrix': {\n",
    "            'tp': int(tp), 'tn': int(tn), \n",
    "            'fp': int(fp), 'fn': int(fn)\n",
    "        }\n",
    "    }\n",
    "\n",
    "def print_metrics(metrics, name=\"Model\"):\n",
    "    print(f\"\\n{name} Performance Metrics:\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1_score']:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {metrics['balanced_accuracy']:.4f}\")\n",
    "    \n",
    "    cm = metrics['confusion_matrix']\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"TP: {cm['tp']}, TN: {cm['tn']}\")\n",
    "    print(f\"FP: {cm['fp']}, FN: {cm['fn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_rbfn(X, y, param_grid, cv=3):\n",
    "    param_combos = []\n",
    "    for centers in param_grid['num_centers']:\n",
    "        for sigma in param_grid['sigma']:\n",
    "            param_combos.append({'num_centers': centers, 'sigma': sigma})\n",
    "    \n",
    "    total_combos = len(param_combos)\n",
    "    print(f\"Testing {total_combos} parameter combinations with {cv}-fold CV\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "    for combo_idx, params in enumerate(param_combos):\n",
    "        print(f\"\\nTesting combination {combo_idx+1}/{total_combos}:\")\n",
    "        print(f\"  num_centers={params['num_centers']}, sigma={params['sigma']}\")\n",
    "\n",
    "        fold_metrics = []\n",
    "\n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "            X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "            y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "            \n",
    "            model = MyRBFN(num_centers=params['num_centers'], sigma=params['sigma'])\n",
    "            t_start = time.time()\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            train_time = time.time() - t_start\n",
    "            \n",
    "            y_val_pred = model.predict(X_val_fold)\n",
    "            metrics = evaluate_model(y_val_fold, y_val_pred)\n",
    "            metrics['training_time'] = train_time\n",
    "            fold_metrics.append(metrics)\n",
    "            \n",
    "            print(f\"  Fold {fold_idx+1}: Accuracy={metrics['accuracy']:.4f}, Time={train_time:.2f}s\")\n",
    "        \n",
    "        avg_metrics = {\n",
    "            'accuracy': np.mean([m['accuracy'] for m in fold_metrics]),\n",
    "            'f1_score': np.mean([m['f1_score'] for m in fold_metrics]),\n",
    "            'balanced_accuracy': np.mean([m['balanced_accuracy'] for m in fold_metrics]),\n",
    "            'training_time': np.mean([m['training_time'] for m in fold_metrics])\n",
    "        }\n",
    "        \n",
    "        result = {\n",
    "            'params': params.copy(),\n",
    "            'avg_metrics': avg_metrics,\n",
    "            'fold_metrics': fold_metrics\n",
    "        }\n",
    "        all_results.append(result)\n",
    "        \n",
    "        print(f\"  Average: Accuracy={avg_metrics['accuracy']:.4f}, F1={avg_metrics['f1_score']:.4f}\")\n",
    "        print(\"-----\"*5)\n",
    "    \n",
    "    best_result = max(all_results, key=lambda x: x['avg_metrics']['accuracy'])\n",
    "    best_params = best_result['params']\n",
    "    \n",
    "    sorted_results = sorted(all_results, key=lambda x: x['avg_metrics']['accuracy'], reverse=True)\n",
    "    \n",
    "    print(\"\\nGrid Search Results:\")\n",
    "    print(f\"Best parameters: num_centers={best_params['num_centers']}, sigma={best_params['sigma']}\")\n",
    "    print(f\"Best validation accuracy: {best_result['avg_metrics']['accuracy']:.4f}\")\n",
    "    \n",
    "    print(\"\\nTop 5 parameter combinations:\")\n",
    "    for i, result in enumerate(sorted_results[:5]):\n",
    "        params = result['params']\n",
    "        acc = result['avg_metrics']['accuracy']\n",
    "        f1 = result['avg_metrics']['f1_score']\n",
    "        time_taken = result['avg_metrics']['training_time']\n",
    "        print(f\"{i+1}. num_centers={params['num_centers']}, sigma={params['sigma']} - \"\n",
    "              f\"Acc={acc:.4f}, F1={f1:.4f}, Time={time_taken:.2f}s\")\n",
    "    \n",
    "    return best_params, all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {'num_centers': [30, 50, 70, 100], 'sigma': [0.1, 0.5, 1.0, 2.0, 5.0]}\n",
    "\n",
    "# best_hp, hp_results = grid_search_rbfn(X, y, param_grid, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'num_centers': [70, 100, 120,140],\n",
    "#     'sigma': [2.0, 5.0, 7.0, 8.0, 9.0]\n",
    "# }\n",
    "\n",
    "# best_hp, hp_results = grid_search_rbfn(X, y, param_grid, cv=3)\n",
    "\n",
    "# centers_list = sorted(list(set([r['params']['num_centers'] for r in hp_results])))\n",
    "# sigma_list = sorted(list(set([r['params']['sigma'] for r in hp_results])))\n",
    "\n",
    "# heatmap_data = np.zeros((len(centers_list), len(sigma_list)))\n",
    "# for result in hp_results:\n",
    "#     i = centers_list.index(result['params']['num_centers'])\n",
    "#     j = sigma_list.index(result['params']['sigma'])\n",
    "#     heatmap_data[i, j] = result['avg_metrics']['accuracy']\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.heatmap(heatmap_data, annot=True, fmt='.4f', cmap='viridis',\n",
    "#             xticklabels=sigma_list, yticklabels=centers_list)\n",
    "# plt.xlabel('Sigma')\n",
    "# plt.ylabel('Number of Centers')\n",
    "# plt.title('Grid Search Results: Accuracy by Hyperparameter Combination')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIM6lyE-BA1B"
   },
   "source": [
    "# ***3. Model Performance Evaluation (Task 3)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_rbfn(X, y, num_centers=140, sigma=7.0, n_splits=5, thresholds=[0.5, 0.6, 0.7]):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    cv_results = {threshold: [] for threshold in thresholds}\n",
    "    \n",
    "    print(f\"Performing {n_splits}-fold cross-validation...\")\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"\\nFold {fold+1}/{n_splits}\")\n",
    "        \n",
    "        X_train_fold, X_test_fold = X[train_idx], X[test_idx]\n",
    "        y_train_fold, y_test_fold = y[train_idx], y[test_idx]\n",
    "        \n",
    "        model = MyRBFN(num_centers=num_centers, sigma=sigma)\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        probs = model.predict_proba(X_test_fold)\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            y_pred = (probs >= threshold).astype(int)\n",
    "            metrics = evaluate_model(y_test_fold, y_pred)\n",
    "            cv_results[threshold].append(metrics)\n",
    "            \n",
    "            print(f\"Threshold {threshold}: Accuracy = {metrics['accuracy']:.4f}, F1 = {metrics['f1_score']:.4f}\")\n",
    "    \n",
    "    avg_results = {}\n",
    "    for threshold in thresholds:\n",
    "        avg_results[threshold] = {\n",
    "            'accuracy': np.mean([m['accuracy'] for m in cv_results[threshold]]),\n",
    "            'precision': np.mean([m['precision'] for m in cv_results[threshold]]),\n",
    "            'recall': np.mean([m['recall'] for m in cv_results[threshold]]),\n",
    "            'f1_score': np.mean([m['f1_score'] for m in cv_results[threshold]]),\n",
    "            'balanced_accuracy': np.mean([m['balanced_accuracy'] for m in cv_results[threshold]])\n",
    "        }\n",
    "    \n",
    "    best_threshold = max(avg_results.keys(), key=lambda x: avg_results[x]['accuracy'])\n",
    "    \n",
    "    print(\"\\nCross-Validation Results by Threshold:\")\n",
    "    for threshold, results in avg_results.items():\n",
    "        print(f\"Threshold {threshold}:\")\n",
    "        print(f\"  Accuracy: {results['accuracy']:.4f}\")\n",
    "        print(f\"  F1 Score: {results['f1_score']:.4f}\")\n",
    "        print(f\"  Balanced Accuracy: {results['balanced_accuracy']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nBest threshold: {best_threshold} (Accuracy: {avg_results[best_threshold]['accuracy']:.4f})\")\n",
    "    \n",
    "    return best_threshold, avg_results, cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 5-fold cross-validation...\n",
      "\n",
      "Fold 1/5\n",
      "Finding centers using K-means...\n",
      "Calculating interpolation matrix...\n",
      "Solving for weights...\n",
      "Training accuracy: 0.9140\n",
      "Threshold 0.5: Accuracy = 0.6793, F1 = 0.7749\n",
      "Threshold 0.55: Accuracy = 0.8323, F1 = 0.8673\n",
      "Threshold 0.6: Accuracy = 0.9010, F1 = 0.9142\n",
      "Threshold 0.65: Accuracy = 0.8932, F1 = 0.8956\n",
      "Threshold 0.7: Accuracy = 0.8287, F1 = 0.8172\n",
      "\n",
      "Fold 2/5\n",
      "Finding centers using K-means...\n",
      "Calculating interpolation matrix...\n",
      "Solving for weights...\n",
      "Training accuracy: 0.9122\n",
      "Threshold 0.5: Accuracy = 0.6640, F1 = 0.7614\n",
      "Threshold 0.55: Accuracy = 0.8337, F1 = 0.8656\n",
      "Threshold 0.6: Accuracy = 0.9002, F1 = 0.9113\n",
      "Threshold 0.65: Accuracy = 0.8925, F1 = 0.8923\n",
      "Threshold 0.7: Accuracy = 0.8385, F1 = 0.8241\n",
      "\n",
      "Fold 3/5\n",
      "Finding centers using K-means...\n",
      "Calculating interpolation matrix...\n",
      "Solving for weights...\n",
      "Training accuracy: 0.9134\n",
      "Threshold 0.5: Accuracy = 0.6807, F1 = 0.7771\n",
      "Threshold 0.55: Accuracy = 0.8383, F1 = 0.8727\n",
      "Threshold 0.6: Accuracy = 0.9095, F1 = 0.9226\n",
      "Threshold 0.65: Accuracy = 0.8988, F1 = 0.9023\n",
      "Threshold 0.7: Accuracy = 0.8337, F1 = 0.8251\n",
      "\n",
      "Fold 4/5\n",
      "Finding centers using K-means...\n",
      "Calculating interpolation matrix...\n",
      "Solving for weights...\n",
      "Training accuracy: 0.9153\n",
      "Threshold 0.5: Accuracy = 0.7047, F1 = 0.7949\n",
      "Threshold 0.55: Accuracy = 0.8478, F1 = 0.8819\n",
      "Threshold 0.6: Accuracy = 0.9093, F1 = 0.9237\n",
      "Threshold 0.65: Accuracy = 0.8945, F1 = 0.9011\n",
      "Threshold 0.7: Accuracy = 0.8207, F1 = 0.8155\n",
      "\n",
      "Fold 5/5\n",
      "Finding centers using K-means...\n",
      "Calculating interpolation matrix...\n",
      "Solving for weights...\n",
      "Training accuracy: 0.9156\n",
      "Threshold 0.5: Accuracy = 0.6870, F1 = 0.7818\n",
      "Threshold 0.55: Accuracy = 0.8367, F1 = 0.8722\n",
      "Threshold 0.6: Accuracy = 0.9030, F1 = 0.9174\n",
      "Threshold 0.65: Accuracy = 0.9032, F1 = 0.9090\n",
      "Threshold 0.7: Accuracy = 0.8433, F1 = 0.8380\n",
      "\n",
      "Cross-Validation Results by Threshold:\n",
      "Threshold 0.5:\n",
      "  Accuracy: 0.6832\n",
      "  F1 Score: 0.7780\n",
      "  Balanced Accuracy: 0.6430\n",
      "Threshold 0.55:\n",
      "  Accuracy: 0.8377\n",
      "  F1 Score: 0.8719\n",
      "  Balanced Accuracy: 0.8179\n",
      "Threshold 0.6:\n",
      "  Accuracy: 0.9046\n",
      "  F1 Score: 0.9178\n",
      "  Balanced Accuracy: 0.8978\n",
      "Threshold 0.65:\n",
      "  Accuracy: 0.8964\n",
      "  F1 Score: 0.9001\n",
      "  Balanced Accuracy: 0.9038\n",
      "Threshold 0.7:\n",
      "  Accuracy: 0.8330\n",
      "  F1 Score: 0.8240\n",
      "  Balanced Accuracy: 0.8498\n",
      "\n",
      "Best threshold: 0.6 (Accuracy: 0.9046)\n"
     ]
    }
   ],
   "source": [
    "best_threshold, avg_metrics, fold_metrics = cross_validate_rbfn(\n",
    "    X, y, \n",
    "    num_centers=140, \n",
    "    sigma=7.0,\n",
    "    thresholds=[0.5, 0.55, 0.6, 0.65, 0.7]\n",
    ")\n",
    "\n",
    "thresholds = list(avg_metrics.keys())\n",
    "accuracies = [avg_metrics[t]['accuracy'] for t in thresholds]\n",
    "f1_scores = [avg_metrics[t]['f1_score'] for t in thresholds]\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(thresholds, accuracies, 'o-', label='Accuracy')\n",
    "# plt.plot(thresholds, f1_scores, 's-', label='F1 Score')\n",
    "# plt.axvline(x=best_threshold, color='r', linestyle='--', label=f'Best Threshold = {best_threshold}')\n",
    "# plt.xlabel('Threshold')\n",
    "# plt.ylabel('Score')\n",
    "# plt.title('Performance Metrics by Threshold')\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iCUL48FBwlQ"
   },
   "source": [
    "# ***4. Performance Evaluation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 16000 samples\n",
      "Test set: 4000 samples\n",
      "Finding centers using K-means...\n",
      "Calculating interpolation matrix...\n",
      "Solving for weights...\n",
      "Training accuracy: 0.9159\n",
      "\n",
      "Training Set Performance Metrics:\n",
      "Accuracy: 0.9066\n",
      "Precision: 0.8812\n",
      "Recall: 0.9622\n",
      "F1 Score: 0.9199\n",
      "Balanced Accuracy: 0.8993\n",
      "\n",
      "Confusion Matrix:\n",
      "TP: 8587, TN: 5918\n",
      "FP: 1158, FN: 337\n",
      "\n",
      "Test Set Performance Metrics:\n",
      "Accuracy: 0.8988\n",
      "Precision: 0.8735\n",
      "Recall: 0.9552\n",
      "F1 Score: 0.9125\n",
      "Balanced Accuracy: 0.8921\n",
      "\n",
      "Confusion Matrix:\n",
      "TP: 2113, TN: 1482\n",
      "FP: 306, FN: 99\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "final_model = MyRBFN(num_centers=140, sigma=7.0)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "train_probs = final_model.predict_proba(X_train)\n",
    "test_probs = final_model.predict_proba(X_test)\n",
    "\n",
    "y_train_pred = (train_probs > best_threshold).astype(int)\n",
    "y_test_pred = (test_probs > best_threshold).astype(int)\n",
    "\n",
    "train_metrics = evaluate_model(y_train, y_train_pred)\n",
    "test_metrics = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "print_metrics(train_metrics, name=\"Training Set\")\n",
    "print_metrics(test_metrics, name=\"Test Set\")\n",
    "\n",
    "test_probs = final_model.predict_proba(X_test)\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(test_probs[y_test == 0], bins=30, alpha=0.5, label='Class 0 (Normal)')\n",
    "# plt.hist(test_probs[y_test == 1], bins=30, alpha=0.5, label='Class 1 (Attack)')\n",
    "# plt.axvline(x=best_threshold, color='red', linestyle='--', \n",
    "#             label=f'Threshold = {best_threshold}')\n",
    "# plt.title('Probability Distribution by Class')\n",
    "# plt.xlabel('Predicted Probability for Class 1')\n",
    "# plt.ylabel('Count')\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.show()\n",
    "\n",
    "# cm = test_metrics['confusion_matrix']\n",
    "# cm_matrix = [[cm['tn'], cm['fp']], [cm['fn'], cm['tp']]]\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "#             xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "#             yticklabels=['Actual 0', 'Actual 1'])\n",
    "# plt.title(f'Confusion Matrix (Threshold = {best_threshold})')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded test set 1 with 4000 samples\n",
      "\n",
      "External Test Set (Test Set 1) Performance Metrics:\n",
      "Accuracy: 0.9093\n",
      "Precision: 0.9671\n",
      "Recall: 0.8956\n",
      "F1 Score: 0.9300\n",
      "Balanced Accuracy: 0.9165\n",
      "\n",
      "Confusion Matrix:\n",
      "TP: 2411, TN: 1226\n",
      "FP: 82, FN: 281\n",
      "\n",
      "Required accuracy: 0.85\n",
      "Achieved accuracy: 0.9093\n",
      "Requirement met: True\n"
     ]
    }
   ],
   "source": [
    "test_data1 = pd.read_csv('UNSWNB15_testing1_coursework.csv')\n",
    "print(f\"Loaded test set 1 with {test_data1.shape[0]} samples\")\n",
    "\n",
    "test_encoded = one_hot_encode(test_data1, cats_to_encode)\n",
    "test_encoded = encode_protocol(test_encoded, column='proto', top_n=10)\n",
    "\n",
    "for col in X_cols:\n",
    "    if col not in test_encoded.columns:\n",
    "        print(f\"Adding missing column: {col}\")\n",
    "        test_encoded[col] = 0\n",
    "\n",
    "test_std = pd.DataFrame()\n",
    "for col in X_cols:\n",
    "    if col in scaler_params:\n",
    "        mean = scaler_params[col]['mean']\n",
    "        std = scaler_params[col]['std']\n",
    "        if std > 0:\n",
    "            test_std[col] = (test_encoded[col] - mean) / std\n",
    "        else:\n",
    "            test_std[col] = 0\n",
    "    else:\n",
    "        test_std[col] = test_encoded[col]\n",
    "\n",
    "X_test1 = test_std[X_cols].values\n",
    "y_test1 = test_data1['label'].values\n",
    "\n",
    "test1_probs = final_model.predict_proba(X_test1)\n",
    "y_test1_pred = (test1_probs >= best_threshold).astype(int)\n",
    "\n",
    "test1_metrics = evaluate_model(y_test1, y_test1_pred)\n",
    "print_metrics(test1_metrics, name=\"External Test Set (Test Set 1)\")\n",
    "\n",
    "required_accuracy = 0.85\n",
    "achieved = test1_metrics['accuracy'] >= required_accuracy\n",
    "print(f\"\\nRequired accuracy: {required_accuracy:.2f}\")\n",
    "print(f\"Achieved accuracy: {test1_metrics['accuracy']:.4f}\")\n",
    "print(f\"Requirement met: {achieved}\")\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(test1_probs[y_test1 == 0], bins=30, alpha=0.5, label='Normal (0)')\n",
    "# plt.hist(test1_probs[y_test1 == 1], bins=30, alpha=0.5, label='Attack (1)')\n",
    "# plt.axvline(x=best_threshold, color='red', linestyle='--', \n",
    "#             label=f'Threshold = {best_threshold}')\n",
    "# plt.title('Test Set 1 - Probability Distribution by Class')\n",
    "# plt.xlabel('Predicted Probability for Attack Class')\n",
    "# plt.ylabel('Count')\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded unlabeled test set 2 with 25 samples\n",
      "Adding missing column: proto_other\n",
      "Adding missing column: state_REQ\n",
      "\n",
      "Predictions for Test Set 2:\n",
      "Samples classified as Normal (0): 9\n",
      "Samples classified as Attack (1): 16\n",
      "Percentage of attacks: 64.00%\n",
      "Saved predictions to test_set2_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "test_data2 = pd.read_csv('UNSWNB15_testing2_coursework_no_label.csv')\n",
    "print(f\"Loaded unlabeled test set 2 with {test_data2.shape[0]} samples\")\n",
    "\n",
    "test2_encoded = one_hot_encode(test_data2, cats_to_encode)\n",
    "test2_encoded = encode_protocol(test2_encoded, column='proto', top_n=10)\n",
    "\n",
    "for col in X_cols:\n",
    "    if col not in test2_encoded.columns:\n",
    "        print(f\"Adding missing column: {col}\")\n",
    "        test2_encoded[col] = 0\n",
    "\n",
    "test2_std = pd.DataFrame()\n",
    "for col in X_cols:\n",
    "    if col in scaler_params:\n",
    "        mean = scaler_params[col]['mean']\n",
    "        std = scaler_params[col]['std']\n",
    "        if std > 0:\n",
    "            test2_std[col] = (test2_encoded[col] - mean) / std\n",
    "        else:\n",
    "            test2_std[col] = 0\n",
    "    else:\n",
    "        test2_std[col] = test2_encoded[col]\n",
    "\n",
    "X_test2 = test2_std[X_cols].values\n",
    "test2_probs = final_model.predict_proba(X_test2)\n",
    "y_test2_pred = (test2_probs >= best_threshold).astype(int)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Index': range(len(y_test2_pred)),\n",
    "    'Predicted_Label': y_test2_pred,\n",
    "    'Probability': test2_probs\n",
    "})\n",
    "\n",
    "print(\"\\nPredictions for Test Set 2:\")\n",
    "print(f\"Samples classified as Normal (0): {np.sum(y_test2_pred == 0)}\")\n",
    "print(f\"Samples classified as Attack (1): {np.sum(y_test2_pred == 1)}\")\n",
    "print(f\"Percentage of attacks: {np.mean(y_test2_pred) * 100:.2f}%\")\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(test2_probs, bins=30, color='skyblue')\n",
    "# plt.axvline(x=best_threshold, color='red', linestyle='--', \n",
    "#             label=f'Threshold = {best_threshold}')\n",
    "# plt.title('Test Set 2 - Probability Distribution')\n",
    "# plt.xlabel('Predicted Probability for Attack Class')\n",
    "# plt.ylabel('Count')\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.show()\n",
    "\n",
    "results_path = 'test_set2_predictions.csv'\n",
    "results_df.to_csv(results_path, index=False)\n",
    "print(f\"Saved predictions to {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_8B_MxvCnf3"
   },
   "source": [
    "| **Sample ID** |**Predicted Label** |\n",
    "| --- | --- |\n",
    "| 1 |  1 |\n",
    "| 2 | 0  |\n",
    "| 3 | 1  |\n",
    "| 4 |  1 |\n",
    "| 5 | 0  |\n",
    "| 6 | 1  |\n",
    "| 7 | 0  |\n",
    "| 8 |  0 |\n",
    "| 9 | 1  |\n",
    "| 10 | 0  |\n",
    "| 11 |  0 |\n",
    "| 12 |  1 |\n",
    "| 13 | 1  |\n",
    "| 14 | 1  |\n",
    "| 15 | 1  |\n",
    "| 16 | 0  |\n",
    "| 17 | 1  |\n",
    "| 18 | 1  |\n",
    "| 19 | 0  |\n",
    "| 20 |  1 |\n",
    "| 21 | 1  |\n",
    "| 22 | 1  |\n",
    "| 23 |  0 |\n",
    "| 24 | 1  |\n",
    "| 25 | 1  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test2_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test = [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,Â 1,Â 1,Â 0,Â 1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = [0,0,1,1,0,1,0,0,1,0,0,1,1,1,1,0,1,1,0,1,1,1,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2_pred == xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test == xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
